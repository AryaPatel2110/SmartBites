{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cb8c8a",
   "metadata": {},
   "source": [
    "# ðŸ½ï¸ Hybrid Restaurant Recommendation System using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf38fe7",
   "metadata": {},
   "source": [
    "\n",
    "This notebook implements a **hybrid recommendation system** using the Yelp dataset filtered for Philadelphia.  \n",
    "We combine collaborative filtering (ALS model) with content-based filtering (TF-IDF on business categories), enhanced by cosine similarity for hybrid re-ranking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b91da1d",
   "metadata": {},
   "source": [
    "\n",
    "| Step              | Purpose                                                     |\n",
    "|-------------------|-------------------------------------------------------------|\n",
    "| **ALS Model**     | Learns collaborative signals (userâ€“business preferences)    |\n",
    "| **TF-IDF**        | Captures business similarity based on categories            |\n",
    "| **Cosine Similarity** | Matches recommended businesses with user's taste       |\n",
    "| **Hybrid Scoring**| Combines both to boost recommendation relevance             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9f35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode, collect_list, concat_ws, avg\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, Normalizer, StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "import utils.config as config\n",
    "\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-22'\n",
    "os.environ['SPARK_HOME'] = r'D:\\Aditya\\Graduate Materials\\Spring 2026\\Big Data\\Project\\spark'\n",
    "# os.environ['SPARK_HOME'] = config.APP\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python3'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable \n",
    "\n",
    "# Spark config \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HybridRecommender\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"false\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Load data\n",
    "\n",
    "review_df = spark.read.json(config.PHILADELPHIA)\n",
    "user_df = spark.read.json(config.USER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74312b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract business metadata\n",
    "business_df = review_df.select(\"business_id\", \"categories\", \"business_stars\").dropna(subset=[\"categories\"])\n",
    "business_df = business_df.withColumn(\"category\", explode(split(col(\"categories\"), \",\\\\s*\")))\n",
    "\n",
    "business_grouped = business_df.groupBy(\"business_id\", \"business_stars\") \\\n",
    "    .agg(concat_ws(\" \", collect_list(\"category\")).alias(\"category_text\"))\n",
    "\n",
    "# TF-IDF pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"category_text\", outputCol=\"words\")\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
    "normalizer = Normalizer(inputCol=\"tfidf_features\", outputCol=\"norm_features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, vectorizer, idf, normalizer])\n",
    "tfidf_model = pipeline.fit(business_grouped)\n",
    "tfidf_business = tfidf_model.transform(business_grouped).select(\"business_id\", \"business_stars\", \"norm_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625ae41c-16b5-412b-9665-8b721576390a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(business_id='-0eUa8TsXFFy0FCxHYmrjg', categories='Caterers, Sandwiches, Delis, Restaurants, Cafes, Event Planning & Services', business_stars=4.0, category='Caterers')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f53723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Index users and businesses\n",
    "indexer_user = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\")\n",
    "indexer_business = StringIndexer(inputCol=\"business_id\", outputCol=\"business_index\")\n",
    "indexed_model = Pipeline(stages=[indexer_user, indexer_business]).fit(review_df)\n",
    "\n",
    "indexed_data = indexed_model.transform(review_df).select(\"user_index\", \"business_index\", \"business_stars\")\n",
    "\n",
    "# Train ALS model\n",
    "als = ALS(userCol=\"user_index\", itemCol=\"business_index\", ratingCol=\"business_stars\",\n",
    "          coldStartStrategy=\"drop\", nonnegative=True, implicitPrefs=False,\n",
    "          rank=10, maxIter=10, regParam=0.1)\n",
    "als_model = als.fit(indexed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d876364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top-N ALS\n",
    "user_recs = als_model.recommendForAllUsers(10)\n",
    "recs_exploded = user_recs.withColumn(\"rec\", explode(\"recommendations\")) \\\n",
    "    .select(\"user_index\", col(\"rec.business_index\").alias(\"business_index\"), col(\"rec.rating\").alias(\"als_score\"))\n",
    "\n",
    "# User history (positive feedback)\n",
    "user_history = review_df.select(\"user_id\", \"business_id\", \"business_stars\").filter(\"business_stars >= 4\")\n",
    "user_history = indexed_model.transform(user_history).select(\"user_index\", \"business_index\", \"business_id\")\n",
    "\n",
    "# Join TF-IDF\n",
    "als_with_tfidf = recs_exploded.join(tfidf_business, recs_exploded.business_index == tfidf_business.business_id)\n",
    "user_history_with_tfidf = user_history.join(tfidf_business, \"business_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9906ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Convert VectorUDT to array\n",
    "vector_to_array_udf = udf(lambda v: v.toArray().tolist() if v is not None else [], ArrayType(DoubleType()))\n",
    "als_with_tfidf = als_with_tfidf.withColumn(\"als_array\", vector_to_array_udf(\"norm_features\"))\n",
    "user_history_with_tfidf = user_history_with_tfidf.withColumn(\"uh_array\", vector_to_array_udf(\"norm_features\"))\n",
    "\n",
    "# Cross join user history with recommendations\n",
    "user_cross = user_history_with_tfidf.alias(\"uh\").join(\n",
    "    als_with_tfidf.alias(\"als\"),\n",
    "    col(\"uh.user_index\") == col(\"als.user_index\")\n",
    ").select(\n",
    "    col(\"als.user_index\").alias(\"user_index\"),\n",
    "    col(\"als.business_id\").alias(\"rec_business\"),\n",
    "    col(\"als.als_score\"),\n",
    "    col(\"uh.business_id\").alias(\"hist_business\"),\n",
    "    col(\"uh.uh_array\"),\n",
    "    col(\"als.als_array\")\n",
    ")\n",
    "\n",
    "# Compute cosine similarity (dot product since vectors are normalized)\n",
    "user_cross = user_cross.withColumn(\n",
    "    \"similarity\",\n",
    "    F.expr(\"aggregate(zip_with(uh_array, als_array, (x, y) -> x * y), 0D, (acc, x) -> acc + x)\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12df4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+--------------+-----------+\n",
      "|user_index|rec_business|als_score|avg_similarity|final_score|\n",
      "+----------+------------+---------+--------------+-----------+\n",
      "+----------+------------+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Average similarity score\n",
    "avg_sim = user_cross.groupBy(\"user_index\", \"rec_business\", \"als_score\") \\\n",
    "    .agg(avg(\"similarity\").alias(\"avg_similarity\"))\n",
    "\n",
    "# Combine ALS score and similarity\n",
    "final_recs = avg_sim.withColumn(\n",
    "    \"final_score\", 0.7 * col(\"als_score\") + 0.3 * col(\"avg_similarity\")\n",
    ").orderBy(\"user_index\", col(\"final_score\").desc())\n",
    "\n",
    "final_recs.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625bc7a-bb2e-4e5f-aec5-2e469623efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
